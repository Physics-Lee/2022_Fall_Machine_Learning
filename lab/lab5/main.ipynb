{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in common use\n",
    "def min_max_normalization(data):\n",
    "    return (data - np.min(data, axis = 0))/(np.max(data, axis = 0) - np.min(data, axis = 0))\n",
    "\n",
    "def concatenate_two_1D_array(X1,X2):\n",
    "    return np.concatenate((X1.reshape(len(X1),1),X2.reshape(len(X2),1)),axis=1)\n",
    "\n",
    "def sort_by_row_in_2D_array_descending(X,row_number):\n",
    "    ind = np.argsort(-X[:,row_number])\n",
    "    return X[ind,:]\n",
    "\n",
    "def select_feature(X,selected_feature):\n",
    "    return X[:,selected_feature]\n",
    "\n",
    "def accuracy(y,y_pred):\n",
    "    return sum(y_pred == y)/len(y_pred == y)\n",
    "\n",
    "def save_ndarray_to_csv(X,filename):\n",
    "    X = pd.DataFrame(X)\n",
    "    X.to_csv(\"{}.csv\".format(filename), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split categorical feature and continuous feature\n",
    "# judge\n",
    "def Is_Continuous(X_train, unique_value_threshold):\n",
    "    return np.array([len(np.unique(X_train[:,i])) > unique_value_threshold for i in range(X_train.shape[1])])\n",
    "\n",
    "# check len unique\n",
    "def check_len_unique(X_train):\n",
    "    len_unique = np.zeros(X_train.shape[1])\n",
    "    for i in range(X_train.shape[1]):\n",
    "        len_unique[i] = len(np.unique(X_train[:, i]))\n",
    "    return len_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELIEF-F\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def diff(x_1,x_2,is_categorical):\n",
    "    if is_categorical == True: # categorical\n",
    "        if x_1 == x_2:\n",
    "            return 0\n",
    "        if x_1 != x_2:\n",
    "            return 1\n",
    "    if is_categorical == False: # continuous\n",
    "        return np.abs(x_1 - x_2)\n",
    "\n",
    "def reliefF(X_train, y_train, n_neighbors, is_categorical):\n",
    "    \n",
    "    # prepare\n",
    "    n_samples, n_features = X_train.shape\n",
    "    weight_of_feature = np.zeros(n_features)\n",
    "\n",
    "    # get the frequency of each label in y_train\n",
    "    counts = np.bincount(y_train)\n",
    "    frequency = counts / y_train.shape\n",
    "    \n",
    "    # use NearestNeighbors of sklearn to get enough neighbors\n",
    "    n_multiple = 10 # With lab5's ball-like bad data, 10x is enough\n",
    "    neigh = NearestNeighbors(n_neighbors = n_neighbors * len(counts) * n_multiple + 1, metric='minkowski', p = 1) # len(counts) = 4\n",
    "    neigh.fit(X_train)\n",
    "    _, hit_miss_indices = neigh.kneighbors(X_train)\n",
    "    hit_miss_indices = hit_miss_indices[:, 1:]\n",
    "    \n",
    "    # for each sample i\n",
    "    for i in range(n_samples):\n",
    "\n",
    "        # get hit indices, the amount equals n_neighbors\n",
    "        hit_indices = hit_miss_indices[i][y_train[hit_miss_indices[i]] == y_train[i]]\n",
    "        if len(hit_indices) < n_neighbors:\n",
    "            raise ValueError(\"length of hit_indices is less than n_neighbors\")\n",
    "        else:\n",
    "            hit_indices = hit_indices[0:n_neighbors]\n",
    "        \n",
    "        # get miss indices, the amount equals n_neighbors for each miss class\n",
    "        miss_indices = hit_miss_indices[i][y_train[hit_miss_indices[i]] != y_train[i]]        \n",
    "        miss_label = y_train[miss_indices]\n",
    "        miss_ind_and_label = np.concatenate((miss_indices.reshape(len(miss_indices),1),miss_label.reshape(len(miss_label),1)),axis=1)\n",
    "        label = np.unique(miss_ind_and_label[:,1])\n",
    "        count = np.zeros(len(label))\n",
    "        delete = []        \n",
    "        for k in range(miss_ind_and_label.shape[0]): # for each row k of miss_ind_and_label\n",
    "            for l in range(len(label)): # len(label) is the number of class in y_train minus 1\n",
    "                if miss_ind_and_label[k,1] == label[l]:\n",
    "                    count[l] += 1\n",
    "                    if count[l] >= n_neighbors + 1:\n",
    "                        delete.append(k)\n",
    "        miss_ind_and_label = np.delete(miss_ind_and_label, delete, axis = 0)\n",
    "        if miss_ind_and_label.shape[0] != (len(label))*n_neighbors:\n",
    "            raise ValueError(\"length of miss_indices is less than n_neighbors\")\n",
    "        miss_indices = miss_ind_and_label[:,0]\n",
    "\n",
    "        # for each feature j\n",
    "        for j in range(n_features):\n",
    "            for hit_idx in hit_indices:      \n",
    "                weight_of_feature[j] -= diff(X_train[i, j],X_train[hit_idx, j],is_categorical[j]) / n_neighbors\n",
    "            for miss_idx in miss_indices:\n",
    "                weight_of_miss = frequency[y_train[miss_idx]]/(1 - frequency[y_train[i]]) # calculate weighted average of miss classes\n",
    "                weight_of_feature[j] += diff(X_train[i, j],X_train[miss_idx, j],is_categorical[j]) / n_neighbors * weight_of_miss\n",
    "\n",
    "    return weight_of_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I mutual\n",
    "def run_many_times_for_continuous_features_to_calculate_I_mutual(X_train_continuous_features,y_train,n_sample,n_loop,n_continuous):\n",
    "    I_mutual_sum = np.zeros(n_continuous)\n",
    "    for i in range(n_loop):\n",
    "        df = np.concatenate((X_train_continuous_features, y_train.reshape(len(y_train),1)), axis = 1)\n",
    "        np.random.shuffle(df)\n",
    "        df = df[0:n_sample, :]\n",
    "        discrete_vars = np.zeros((n_continuous,), dtype=bool)\n",
    "        I_mutual = mutual_info_classif(df[:,0:n_continuous], df[:,n_continuous], discrete_features = discrete_vars)\n",
    "        I_mutual_sum = I_mutual_sum + I_mutual\n",
    "    I_mutual_average = I_mutual_sum / n_loop\n",
    "    return I_mutual_average\n",
    "\n",
    "# you may use this function if you choose more categorical features than 23\n",
    "def discretize_by_decimal_place(categorical_features, decimal_places):\n",
    "    categorical_features_rounded = np.round(categorical_features, decimal_places)\n",
    "    return categorical_features_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def plot_2D(train_feature_2D, train_label):\n",
    "\n",
    "    # concatenate to stain the dots\n",
    "    df = np.concatenate((train_feature_2D, train_label), axis=1)\n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    colors_list = [\"r\", \"g\", \"b\", \"k\"]\n",
    "    ax1.scatter(df[:, 0], df[:, 1], c=[colors_list[int(i)] for i in df[:, 2]])\n",
    "\n",
    "def plot_3D(train_feature_3D, train_label):\n",
    "\n",
    "    x = train_feature_3D[:, 0]\n",
    "    y = train_feature_3D[:, 1]\n",
    "    z = train_feature_3D[:, 2]\n",
    "    colors = ['red' if label == 0 else 'blue' if label == 1 else 'green' if label == 2 else 'black' for label in train_label]\n",
    "\n",
    "    trace = go.Scatter3d(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color=colors,\n",
    "            size=12,\n",
    "            symbol='circle',\n",
    "            line=None,\n",
    "            opacity=0.9\n",
    "        )\n",
    "    )\n",
    "    data = [trace]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"3D Scatter Plot\",\n",
    "        scene = dict(\n",
    "            xaxis_title='X-axis',\n",
    "            yaxis_title='Y-axis',\n",
    "            zaxis_title='Z-axis'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read\n",
    "train_feature = pd.read_csv('Dataset/train_feature.csv')\n",
    "train_null = train_feature.isnull().sum() # Checking the Missing Values (nan)\n",
    "train_describe = train_feature.describe() # descriptive statistics\n",
    "\n",
    "test_feature = pd.read_csv('Dataset/test_feature.csv')\n",
    "test_null = test_feature.isnull().sum() # Checking the Missing Values (nan)\n",
    "test_describe = test_feature.describe() # descriptive statistics\n",
    "\n",
    "train_label = pd.read_csv('Dataset/train_label.csv')\n",
    "train_label_count = train_label.value_counts() # count different label\n",
    "\n",
    "# to numpy\n",
    "train_feature = train_feature.to_numpy() \n",
    "test_feature = test_feature.to_numpy()\n",
    "train_label = train_label.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use median to take the place of nan\n",
    "def nan_to_median(train_feature):\n",
    "    median = np.nanmedian(train_feature, axis = 0)\n",
    "    for i in range(train_feature.shape[1]):\n",
    "        train_feature[:, i] = np.where(np.isnan(train_feature[:, i]), median[i], train_feature[:, i])\n",
    "\n",
    "# process train_feature and test_feature\n",
    "nan_to_median(train_feature)\n",
    "nan_to_median(test_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tukey_test(train_feature, IQR_index):\n",
    "    upper_percentile = 75\n",
    "    lower_percentile = 25\n",
    "    upper_bound = np.percentile(train_feature, upper_percentile, axis=0)\n",
    "    lower_bound = np.percentile(train_feature, lower_percentile, axis=0)\n",
    "    IQR = upper_bound - lower_bound    \n",
    "    up_limit = upper_bound + IQR * IQR_index\n",
    "    down_limit = lower_bound - IQR * IQR_index\n",
    "    mask = np.logical_and(train_feature >= down_limit, train_feature <= up_limit) # mask is normal, ~mask is outlier\n",
    "    number_of_outliers = np.sum(~mask)\n",
    "    return number_of_outliers, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### decide IQR index for Tukey test\n",
    "* method 1: draw graph of number of outliers versus IQR index\n",
    "* method 2: compare IQR index by seeing Jupyter variables\n",
    "* method 3: draw histograms of all features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method 1: draw graph of number of outliers versus IQR index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_number_of_outliers_vs_IQR_index(train_feature, IQR_index_max):\n",
    "\n",
    "    # draw graph of number of outliers versus IQR index\n",
    "    count = 0\n",
    "    x = np.arange(2,IQR_index_max,1)\n",
    "    number_of_outliers = np.zeros(x.size)\n",
    "    for IQR_index in x:\n",
    "        number_of_outliers[count], _ = Tukey_test(train_feature, IQR_index)\n",
    "        count = count + 1\n",
    "    fig = plt.figure() \n",
    "    ax1 = fig.add_subplot(111)\n",
    "    plt.xlabel('IQR index') \n",
    "    plt.ylabel('number_of_outliers') \n",
    "    ax1.scatter(x, number_of_outliers)\n",
    "\n",
    "    # create a table of x and number_of_outliers to see them more conveniently\n",
    "    table = np.zeros((len(x),2))\n",
    "    table[:,0] = x\n",
    "    table[:,1] = number_of_outliers\n",
    "    return table\n",
    "\n",
    "# train_feature\n",
    "IQR_index_max = 20\n",
    "table_train = plot_number_of_outliers_vs_IQR_index(train_feature, IQR_index_max)\n",
    "\n",
    "# test_feature\n",
    "IQR_index_max = 20\n",
    "table_test = plot_number_of_outliers_vs_IQR_index(test_feature, IQR_index_max)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method 2: compare IQR index by seeing Jupyter variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_to_median(train_feature, IQR_index): # shallow replicate\n",
    "    _, mask = Tukey_test(train_feature, IQR_index) \n",
    "    median = np.nanmedian(train_feature, axis = 0)\n",
    "    for i in range(train_feature.shape[1]):\n",
    "        train_feature[:, i] = np.where(mask[:,i], train_feature[:, i], median[i]) # mask is normal, ~mask is outlier\n",
    "    return train_feature\n",
    "\n",
    "# check outliers and normal values or train_feature and test_feature\n",
    "\n",
    "# train_feature\n",
    "\n",
    "# train_feature_7 = train_feature.copy()\n",
    "# IQR_index = 7\n",
    "# _ = outliers_to_median(train_feature_7, IQR_index)\n",
    "\n",
    "# train_feature_10 = train_feature.copy()\n",
    "# IQR_index = 10\n",
    "# _ = outliers_to_median(train_feature_10, IQR_index)\n",
    "\n",
    "# train_feature_15 = train_feature.copy()\n",
    "# IQR_index = 15\n",
    "# _ = outliers_to_median(train_feature_15, IQR_index)\n",
    "\n",
    "# train_feature_20 = train_feature.copy()\n",
    "# IQR_index = 20\n",
    "# _ = outliers_to_median(train_feature_20, IQR_index)\n",
    "\n",
    "# test_feature\n",
    "\n",
    "# test_feature_7 = test_feature.copy()\n",
    "# IQR_index = 7\n",
    "# _ = outliers_to_median(test_feature_7, IQR_index)\n",
    "\n",
    "# test_feature_10 = test_feature.copy()\n",
    "# IQR_index = 10\n",
    "# _ = outliers_to_median(test_feature_10, IQR_index)\n",
    "\n",
    "# test_feature_15 = test_feature.copy()\n",
    "# IQR_index = 15\n",
    "# _ = outliers_to_median(test_feature_15, IQR_index)\n",
    "\n",
    "# test_feature_20 = test_feature.copy()\n",
    "# IQR_index = 20\n",
    "# _ = outliers_to_median(test_feature_20, IQR_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method 3: draw histograms of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_all_features(train_feature, filename): # you must create a file named filename in this name before using this function\n",
    "    for i in range(train_feature.shape[1]):\n",
    "        plt.hist(train_feature[:, i], density=False,\n",
    "                bins=30, facecolor=\"blue\", edgecolor=\"black\")\n",
    "        plt.xlabel('feature %i' % i)\n",
    "        plt.ylabel('count')\n",
    "        plt.savefig('{}/fig_{}.png'.format(filename, i))\n",
    "        plt.cla()\n",
    "        \n",
    "def decide_by_hist(train_feature, IQR_index):\n",
    "    train_feature = train_feature.copy() # create a copy of the array, in this way, you can make a deep replicate instead of a shallow replicate\n",
    "    train_feature = outliers_to_median(train_feature, IQR_index)\n",
    "    histogram_all_features(train_feature, 'IQR_index_{}'.format(IQR_index))\n",
    "\n",
    "# check outliers and normal values of train_feature and test_feature by histogram\n",
    "\n",
    "# train_feature\n",
    "# IQR_index = 7\n",
    "# decide_by_hist(train_feature, IQR_index)\n",
    "\n",
    "# test_feature\n",
    "# IQR_index = 7\n",
    "# decide_by_hist(test_feature, IQR_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR_index is a hyper-parameter\n",
    "IQR_index = 15\n",
    "\n",
    "# train_feature\n",
    "train_feature = outliers_to_median(train_feature, IQR_index)\n",
    "\n",
    "# test_feature\n",
    "test_feature = outliers_to_median(test_feature, IQR_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Pearson correlation matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = temp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  69 , Count:  4\n",
      "Index:  92 , Count:  4\n",
      "Index:  5 , Count:  4\n",
      "Index:  73 , Count:  4\n",
      "Index:  89 , Count:  2\n",
      "Index:  50 , Count:  2\n",
      "Index:  82 , Count:  1\n",
      "Index:  79 , Count:  1\n",
      "Index:  80 , Count:  1\n",
      "Index:  81 , Count:  1\n"
     ]
    }
   ],
   "source": [
    "# 根据每一行中绝对值大于 0.7 的元素个数排序，打印前面十项\n",
    "sort_order = corr_matrix.abs().gt(0.7).sum(axis=1).sort_values(ascending=False)\n",
    "for i in sort_order.index[:10]:\n",
    "    print(\"Index: \", i, \", Count: \", sort_order[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train_feature\n",
    "y = train_label\n",
    "\n",
    "# 2 split\n",
    "# Indeed I use 3 split, not 2 split, because afterwards I will use cross-validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "y_train = y_train.reshape(len(y_train),)\n",
    "y_test = y_test.reshape(len(y_test),)\n",
    "\n",
    "# number of samples and features in train set\n",
    "n_sample_of_train_set = X_train.shape[0]\n",
    "n_feature = X_train.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split all features into the continuous and the categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "threshold_of_unique_value = 23 # a hyper-parameter\n",
    "is_continuous = Is_Continuous(X_train, threshold_of_unique_value)\n",
    "is_categorical = ~is_continuous\n",
    "X_train_continuous_features = X_train[:, is_continuous]\n",
    "X_train_categorical_features = X_train[:, ~is_continuous]\n",
    "\n",
    "# store original rank\n",
    "original_rank_continuous = np.where(is_continuous)[0]\n",
    "original_rank_categorical = np.where(~is_continuous)[0]\n",
    "\n",
    "# number of continuous features and categorical features in train set\n",
    "n_continuous = X_train_continuous_features.shape[1]\n",
    "n_categorical = X_train_categorical_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max-normalization\n",
    "X_train = min_max_normalization(X_train)\n",
    "X_test = min_max_normalization(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = min_max_normalization(test_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELIEF-F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELIEF-F\n",
    "n_neigh_RELIEF = 10 # hyper-parameter\n",
    "weight_of_feature = reliefF(X_train, y_train, n_neigh_RELIEF, is_categorical)\n",
    "weight_of_feature_concatenate = concatenate_two_1D_array(weight_of_feature,np.arange(120))\n",
    "weight_of_feature_concatenate = sort_by_row_in_2D_array_descending(weight_of_feature_concatenate,0)\n",
    "\n",
    "# get index of selected feature\n",
    "n_choose_RELIEF = 20 # a hyper-parameter\n",
    "selected_feature_RELIEF = weight_of_feature_concatenate[0:n_choose_RELIEF,1]\n",
    "selected_feature_RELIEF = selected_feature_RELIEF.astype(int)\n",
    "selected_feature_RELIEF = np.sort(selected_feature_RELIEF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # knn\n",
    "# n_choose = 20\n",
    "# result_knn = np.zeros((n_choose*n_neigh_RELIEF,3))\n",
    "# count = 0\n",
    "# for i in range(1,n_choose,1):\n",
    "\n",
    "#     # select top i features\n",
    "#     selected_feature = weight_of_feature_concatenate[0:i,1]\n",
    "#     selected_feature = selected_feature.astype(int)\n",
    "#     selected_feature = np.sort(selected_feature)\n",
    "#     X_train_RELIEF = select_feature(X_train,selected_feature)\n",
    "#     X_test_RELIEF = select_feature(X_test,selected_feature)\n",
    "\n",
    "#     # perform knn\n",
    "#     for n_neigh_knn in np.arange(1,n_neigh_RELIEF + 1,1):\n",
    "#         knn = KNeighborsClassifier(n_neighbors=n_neigh_knn,p = 1,metric = 'minkowski')\n",
    "#         knn.fit(X_train_RELIEF, y_train)\n",
    "#         y_val_pred = knn.predict(X_test_RELIEF)\n",
    "#         result_knn[count,0] = i\n",
    "#         result_knn[count,1] = n_neigh_knn\n",
    "#         result_knn[count,2] = accuracy(y_test,y_val_pred)\n",
    "#         count += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chi2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make chi2 test between each column of X and y\n",
    "\n",
    "# # def\n",
    "# from scipy.stats import chi2_contingency\n",
    "# def chi2_test(X, y):\n",
    "#     chi2_value = []\n",
    "#     p_value = []\n",
    "#     degree_of_freedom = []\n",
    "#     for i in range(X.shape[1]):\n",
    "#         result = chi2_contingency(pd.crosstab(X[:, i], y))\n",
    "#         chi2_value.append(result[0])\n",
    "#         p_value.append(result[1])\n",
    "#         degree_of_freedom.append(result[2])\n",
    "#     number_of_unique_value = np.array(degree_of_freedom) / 3 # to get unique sample count\n",
    "#     return chi2_value, p_value, number_of_unique_value\n",
    "\n",
    "# # chi 2 for categorical feature\n",
    "# chi2_value_categorical_all_sample, p_value_categorical_all_sample, number_of_unique_value_categorical_all_sample \\\n",
    "#      = chi2_test(categorical_features, train_label.reshape(train_label.shape[0]))\n",
    "\n",
    "# # chi 2 for continuous feature\n",
    "# decimal_places = 2 # a hyper-parameter # this is consistent with the 100 threshold of categarical features\n",
    "# continuous_features_rounded = discretize_by_decimal_place(continuous_features, decimal_places)\n",
    "# chi2_value_continuous_all_sample, p_value_continuous_all_sample, number_of_unique_value_continuous_all_sample \\\n",
    "#      = chi2_test(continuous_features_rounded, train_label.reshape(train_label.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sample = 5000 # hyper-parameter # 5000 means 50 for each category\n",
    "# n_continuous = categorical_features.shape[1]\n",
    "# rank_sum = np.zeros(n_continuous)\n",
    "# for i in range(10):\n",
    "#     # shuffle\n",
    "#     df = np.concatenate((categorical_features, train_label), axis = 1)\n",
    "#     np.random.shuffle(df)\n",
    "#     df = df[0:n_sample, :]\n",
    "\n",
    "#     # chi2 test\n",
    "#     _, p_value_of_1_Fold, _ = chi2_test(df[:, 0:df.shape[1]-1], df[:, df.shape[1]-1])\n",
    "\n",
    "#     # add rank\n",
    "#     p_value_of_1_Fold = np.array(p_value_of_1_Fold)\n",
    "#     serial_number = np.arange(n_continuous)\n",
    "#     p_value_of_1_Fold = np.concatenate((serial_number.reshape(n_continuous,1), p_value_of_1_Fold.reshape(n_continuous,1)), axis = 1)\n",
    "#     ind = np.argsort(p_value_of_1_Fold[:,1])\n",
    "#     p_value_of_1_Fold = p_value_of_1_Fold[ind]\n",
    "#     rank = np.arange(n_continuous).reshape(n_continuous,1) + 1\n",
    "#     p_value_of_1_Fold = np.concatenate((p_value_of_1_Fold, rank), axis = 1)\n",
    "#     ind = np.argsort(p_value_of_1_Fold[:,0])\n",
    "#     p_value_of_1_Fold = p_value_of_1_Fold[ind]\n",
    "#     rank_sum = rank_sum + p_value_of_1_Fold[:,2]\n",
    "\n",
    "# sorted_rank_sum = np.sort(rank_sum)\n",
    "# plt.plot(sorted_rank_sum)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Public_repository\\ml_2022_f\\lab\\lab5\\main.ipynb Cell 49\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# continuous feature\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m n_loop \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m I_mutual_continuous_average \u001b[39m=\u001b[39m run_many_times_for_continuous_features_to_calculate_I_mutual(X_train_continuous_features,y_train,n_sample_of_train_set,n_loop,n_continuous)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msort(\u001b[39m-\u001b[39mI_mutual_continuous_average))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mcontinuous feature\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32md:\\Public_repository\\ml_2022_f\\lab\\lab5\\main.ipynb Cell 49\u001b[0m in \u001b[0;36mrun_many_times_for_continuous_features_to_calculate_I_mutual\u001b[1;34m(X_train_continuous_features, y_train, n_sample, n_loop, n_continuous)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     df \u001b[39m=\u001b[39m df[\u001b[39m0\u001b[39m:n_sample, :]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     discrete_vars \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_continuous,), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     I_mutual \u001b[39m=\u001b[39m mutual_info_classif(df[:,\u001b[39m0\u001b[39;49m:n_continuous], df[:,n_continuous], discrete_features \u001b[39m=\u001b[39;49m discrete_vars)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     I_mutual_sum \u001b[39m=\u001b[39m I_mutual_sum \u001b[39m+\u001b[39m I_mutual\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Public_repository/ml_2022_f/lab/lab5/main.ipynb#X66sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m I_mutual_average \u001b[39m=\u001b[39m I_mutual_sum \u001b[39m/\u001b[39m n_loop\n",
      "File \u001b[1;32md:\\Public\\20220221_Anaconda_Install\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:468\u001b[0m, in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Estimate mutual information for a discrete target variable.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \n\u001b[0;32m    396\u001b[0m \u001b[39mMutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[39m       of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    467\u001b[0m check_classification_targets(y)\n\u001b[1;32m--> 468\u001b[0m \u001b[39mreturn\u001b[39;00m _estimate_mi(X, y, discrete_features, \u001b[39mTrue\u001b[39;49;00m, n_neighbors, copy, random_state)\n",
      "File \u001b[1;32md:\\Public\\20220221_Anaconda_Install\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:304\u001b[0m, in \u001b[0;36m_estimate_mi\u001b[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    297\u001b[0m     y \u001b[39m=\u001b[39m scale(y, with_mean\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    298\u001b[0m     y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m         \u001b[39m1e-10\u001b[39m\n\u001b[0;32m    300\u001b[0m         \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmaximum(\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mabs(y)))\n\u001b[0;32m    301\u001b[0m         \u001b[39m*\u001b[39m rng\u001b[39m.\u001b[39mstandard_normal(size\u001b[39m=\u001b[39mn_samples)\n\u001b[0;32m    302\u001b[0m     )\n\u001b[1;32m--> 304\u001b[0m mi \u001b[39m=\u001b[39m [\n\u001b[0;32m    305\u001b[0m     _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)\n\u001b[0;32m    306\u001b[0m     \u001b[39mfor\u001b[39;00m x, discrete_feature \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(_iterate_columns(X), discrete_mask)\n\u001b[0;32m    307\u001b[0m ]\n\u001b[0;32m    309\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(mi)\n",
      "File \u001b[1;32md:\\Public\\20220221_Anaconda_Install\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:305\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    297\u001b[0m     y \u001b[39m=\u001b[39m scale(y, with_mean\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    298\u001b[0m     y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m         \u001b[39m1e-10\u001b[39m\n\u001b[0;32m    300\u001b[0m         \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmaximum(\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mabs(y)))\n\u001b[0;32m    301\u001b[0m         \u001b[39m*\u001b[39m rng\u001b[39m.\u001b[39mstandard_normal(size\u001b[39m=\u001b[39mn_samples)\n\u001b[0;32m    302\u001b[0m     )\n\u001b[0;32m    304\u001b[0m mi \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 305\u001b[0m     _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)\n\u001b[0;32m    306\u001b[0m     \u001b[39mfor\u001b[39;00m x, discrete_feature \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(_iterate_columns(X), discrete_mask)\n\u001b[0;32m    307\u001b[0m ]\n\u001b[0;32m    309\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(mi)\n",
      "File \u001b[1;32md:\\Public\\20220221_Anaconda_Install\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:163\u001b[0m, in \u001b[0;36m_compute_mi\u001b[1;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m _compute_mi_cd(y, x, n_neighbors)\n\u001b[0;32m    162\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m x_discrete \u001b[39mand\u001b[39;00m y_discrete:\n\u001b[1;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m _compute_mi_cd(x, y, n_neighbors)\n\u001b[0;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m _compute_mi_cc(x, y, n_neighbors)\n",
      "File \u001b[1;32md:\\Public\\20220221_Anaconda_Install\\lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:146\u001b[0m, in \u001b[0;36m_compute_mi_cd\u001b[1;34m(c, d, n_neighbors)\u001b[0m\n\u001b[0;32m    139\u001b[0m m_all \u001b[39m=\u001b[39m kd\u001b[39m.\u001b[39mquery_radius(c, radius, count_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_distance\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m m_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(m_all)\n\u001b[0;32m    142\u001b[0m mi \u001b[39m=\u001b[39m (\n\u001b[0;32m    143\u001b[0m     digamma(n_samples)\n\u001b[0;32m    144\u001b[0m     \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mmean(digamma(k_all))\n\u001b[0;32m    145\u001b[0m     \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(digamma(label_counts))\n\u001b[1;32m--> 146\u001b[0m     \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(digamma(m_all))\n\u001b[0;32m    147\u001b[0m )\n\u001b[0;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, mi)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# categorical feature\n",
    "discrete_vars_categorical = np.ones((n_categorical,), dtype=bool)\n",
    "I_mutual_categorical = mutual_info_classif(X_train_categorical_features, y_train.reshape(y_train.shape[0],), discrete_features = discrete_vars_categorical)\n",
    "plt.plot(-np.sort(-I_mutual_categorical))\n",
    "plt.xlabel('categorical feature')\n",
    "plt.ylabel('mutual information')\n",
    "plt.show()\n",
    "I_mutual_categorical = concatenate_two_1D_array(original_rank_categorical,I_mutual_categorical)\n",
    "\n",
    "# continuous feature\n",
    "n_loop = 100\n",
    "I_mutual_continuous_average = run_many_times_for_continuous_features_to_calculate_I_mutual(X_train_continuous_features,y_train,n_sample_of_train_set,n_loop,n_continuous)\n",
    "plt.plot(-np.sort(-I_mutual_continuous_average))\n",
    "plt.xlabel('continuous feature')\n",
    "plt.ylabel('mutual information')\n",
    "plt.show()\n",
    "I_mutual_continuous_average = concatenate_two_1D_array(original_rank_continuous,I_mutual_continuous_average)\n",
    "\n",
    "# get index of selected feature\n",
    "I_mutual = np.concatenate((I_mutual_categorical,I_mutual_continuous_average))\n",
    "I_mutual = sort_by_row_in_2D_array_descending(I_mutual,1)\n",
    "n_choose_I_mutual = 10 # a hyper-parameter\n",
    "selected_feature_I_mutual = I_mutual[0:n_choose_I_mutual,0]\n",
    "selected_feature_I_mutual = selected_feature_I_mutual.astype(int)\n",
    "selected_feature_I_mutual = np.sort(selected_feature_I_mutual)\n",
    "\n",
    "# union1d\n",
    "selected_feature = np.union1d(selected_feature_RELIEF,selected_feature_I_mutual)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrapper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_selection import RFE\n",
    "\n",
    "# # fit\n",
    "# clf_LR = LogisticRegression(multi_class=\"multinomial\", solver='lbfgs', max_iter=10 ** 3)\n",
    "# selector = RFE(estimator = clf_LR, step = 1, n_features_to_select = 10)\n",
    "# selector.fit(X_train_RELIEF_I_mutual, y_train)\n",
    "# X_train_rfe = selector.transform(X_train_RELIEF_I_mutual)\n",
    "# X_validation_rfe = selector.transform(X_val_RELIEF_I_mutual)\n",
    "\n",
    "# # test the transformed data\n",
    "\n",
    "# # fit\n",
    "# clf_LR.fit(X_train_rfe, y_train)\n",
    "\n",
    "# # coef and intercept\n",
    "# a = clf_LR.coef_\n",
    "# b = clf_LR.intercept_\n",
    "\n",
    "# # accuracy of train set\n",
    "# y_train_pred = clf_LR.predict(X_train_rfe)\n",
    "# print(\"accuracy of train set: {}\".format(accuracy(y_train,y_train_pred)))\n",
    "\n",
    "# # accuracy of validation set\n",
    "# y_validation_pred = clf_LR.predict(X_validation_rfe)\n",
    "# print(\"accuracy of validation set: {}\".format(accuracy(y_val,y_validation_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embed method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# lasso = Lasso(alpha = 0.1)\n",
    "# clf = OneVsRestClassifier(lasso)\n",
    "# clf.fit(X_train_RELIEF_I_mutual, y_train)\n",
    "\n",
    "# # accuracy of train set\n",
    "# y_train_pred = clf.predict(X_train_RELIEF_I_mutual)\n",
    "# print(\"accuracy of train set: {}\".format(accuracy(y_train,y_train_pred)))\n",
    "\n",
    "# # accuracy of validation set\n",
    "# y_val_pred = clf.predict(X_val_RELIEF_I_mutual)\n",
    "# print(\"accuracy of validation set: {}\".format(accuracy(y_val,y_val_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 30 features\n",
    "X_train_RELIEF_I_mutual = X_train[:,selected_feature]\n",
    "X_test_RELIEF_I_mutual = X_test[:,selected_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(random_state = 66)\n",
    "score = cross_val_score(DT,X_train_RELIEF_I_mutual,y_train,cv=4).mean()\n",
    "print('基尼系数得分: %.4f'%score)\n",
    "DT = DecisionTreeClassifier(criterion = 'entropy',random_state = 66)\n",
    "score = cross_val_score(DT,X_train_RELIEF_I_mutual,y_train,cv=4).mean()\n",
    "print('熵得分: %.4f'%score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I choose gini index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###在大范围内画出max_depth这个参数变化曲线\n",
    "ScoreAll = []\n",
    "for i in range(10,100,10):\n",
    "    DT = DecisionTreeClassifier(max_depth = i,random_state = 66)\n",
    "    score = cross_val_score(DT,X_train_RELIEF_I_mutual,y_train,cv=4).mean()\n",
    "    ScoreAll.append([i,score])\n",
    "ScoreAll = np.array(ScoreAll)\n",
    "\n",
    "max_score = np.where(ScoreAll==np.max(ScoreAll[:,1]))[0][0]\n",
    "print(\"最优参数以及最高得分:\",ScoreAll[max_score])  \n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(ScoreAll[:,0],ScoreAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###在小范围内画出max_depth这个参数变化曲线\n",
    "ScoreAll = []\n",
    "for i in range(20,40,1):\n",
    "    DT = DecisionTreeClassifier(max_depth = i,random_state = 66)\n",
    "    score = cross_val_score(DT,X_train_RELIEF_I_mutual,y_train,cv=4).mean()\n",
    "    ScoreAll.append([i,score])\n",
    "ScoreAll = np.array(ScoreAll)\n",
    "\n",
    "max_score = np.where(ScoreAll==np.max(ScoreAll[:,1]))[0][0]\n",
    "print(\"最优参数以及最高得分:\",ScoreAll[max_score])  \n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(ScoreAll[:,0],ScoreAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暂定31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单独看看min_samples_split的变化趋势\n",
    "ScoreAll = []\n",
    "for i in range(2,30):\n",
    "    DT = DecisionTreeClassifier(max_depth = 31,min_samples_split = i,random_state = 66)\n",
    "    score = cross_val_score(DT,X_train_RELIEF_I_mutual,y_train,cv=4).mean()\n",
    "    ScoreAll.append([i,score])\n",
    "ScoreAll = np.array(ScoreAll)\n",
    "\n",
    "max_score = np.where(ScoreAll==np.max(ScoreAll[:,1]))[0][0] ##这句话看似很长的，其实就是找出最高得分对应的索引\n",
    "print(\"最优参数以及最高得分:\",ScoreAll[max_score])  \n",
    "# print(ScoreAll[,0])\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(ScoreAll[:,0],ScoreAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暂定6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###调min_samples_leaf这个参数\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ScoreAll = []\n",
    "for i in range(1,30):\n",
    "    DT = DecisionTreeClassifier(min_samples_leaf = i,min_samples_split = 6,max_depth = 31,random_state = 66)\n",
    "    score = cross_val_score(DT,X_train_RELIEF_I_mutual,y_train,cv=4).mean()\n",
    "    ScoreAll.append([i,score])\n",
    "ScoreAll = np.array(ScoreAll)\n",
    "\n",
    "max_score = np.where(ScoreAll==np.max(ScoreAll[:,1]))[0][0] ##这句话看似很长的，其实就是找出最高得分对应的索引\n",
    "print(\"最优参数以及最高得分:\",ScoreAll[max_score])  \n",
    "# print(ScoreAll[,0])\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(ScoreAll[:,0],ScoreAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据我们前边的一系列操作，我们确定因为max_depth在31附近，min_samples_split在6附近，min_samples_leaf在1附近是最优参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_depth、min_samples_leaf和min_samples_split一块儿调整  \n",
    "param_grid = {\n",
    "    'max_depth':np.arange(25, 35),\n",
    "    'min_samples_leaf':np.arange(1, 10),\n",
    "    'min_samples_split':np.arange(1, 10)}\n",
    "\n",
    "rfc = DecisionTreeClassifier(random_state=66)\n",
    "GS = GridSearchCV(rfc,param_grid,cv=4)\n",
    "GS.fit(X_train_RELIEF_I_mutual,y_train)\n",
    "print(GS.best_params_)\n",
    "print(GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = GS.cv_results_\n",
    "my_mean_list = []\n",
    "my_std_list = []\n",
    "my_params_list = []\n",
    "\n",
    "for mean, std, params in zip(results['mean_test_score'], results['std_test_score'], results['params']):\n",
    "    my_mean_list.append(mean)\n",
    "    my_std_list.append(std)\n",
    "    my_params_list.append(params)\n",
    "\n",
    "my_mean_list = np.array(my_mean_list).reshape(len(my_mean_list),1)\n",
    "my_std_list = np.array(my_std_list).reshape(len(my_std_list),1)\n",
    "my_params_list_2 = pd.DataFrame(my_params_list)\n",
    "my_params_list_2 = my_params_list_2.to_numpy()\n",
    "my_GS_result = np.concatenate((my_mean_list,my_std_list),axis=1)\n",
    "my_GS_result = np.concatenate((my_GS_result,my_params_list_2),axis=1)\n",
    "save_ndarray_to_csv(my_GS_result,'GS_result')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综合考虑mean和std，选择31、1、6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(min_samples_leaf = 1,min_samples_split = 6,max_depth = 31,random_state = 66)\n",
    "score = cross_val_score(DT,X_train_RELIEF_I_mutual,y_train,cv=4).mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv = X_train_RELIEF_I_mutual\n",
    "y_cv = y_train\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k = 4 # a hyper-parameter\n",
    "stratified_kf = StratifiedKFold(n_splits = k)\n",
    "importance_DT = np.zeros((len(selected_feature),))\n",
    "y_train_acc_sum = 0\n",
    "y_val_acc_sum = 0\n",
    "for train_index, val_index in stratified_kf.split(X_cv, y_cv):\n",
    "    \n",
    "    # split\n",
    "    X_train_cv, X_val_cv = X_cv[train_index], X_cv[val_index]\n",
    "    y_train_cv, y_val_cv = y_cv[train_index], y_cv[val_index]\n",
    "\n",
    "    # fit\n",
    "    DT = DecisionTreeClassifier(min_samples_leaf = 1,min_samples_split = 6,max_depth = 31,random_state = 66)\n",
    "    DT.fit(X_train_cv, y_train_cv)\n",
    "    # train\n",
    "    y_train_pred = DT.predict(X_train_cv)\n",
    "    y_train_acc = accuracy(y_train_cv,y_train_pred)\n",
    "    print(\"accuracy of train set: {}\".format(y_train_acc))\n",
    "    # val\n",
    "    y_val_pred = DT.predict(X_val_cv)\n",
    "    y_val_acc = accuracy(y_val_cv,y_val_pred)\n",
    "    print(\"accuracy of validation set: {}\".format(y_val_acc))\n",
    "    # importance\n",
    "    importance_DT += DT.feature_importances_\n",
    "    # sum\n",
    "    y_train_acc_sum += y_train_acc\n",
    "    y_val_acc_sum += y_val_acc\n",
    "\n",
    "# print\n",
    "y_train_acc_average = y_train_acc_sum / 4\n",
    "print(\"average accuracy of train set: {}\".format(y_train_acc_average))\n",
    "y_val_acc_average = y_val_acc_sum / 4\n",
    "print(\"average accuracy of val set: {}\".format(y_val_acc_average))\n",
    "\n",
    "# plot\n",
    "plt.plot(-np.sort(-importance_DT))\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('importance of decision tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "importance_DT = concatenate_two_1D_array(np.arange(len(importance_DT)),importance_DT)\n",
    "importance_DT = sort_by_row_in_2D_array_descending(importance_DT,1)\n",
    "n_choose = 28\n",
    "temp = importance_DT[0:n_choose,0]\n",
    "temp = temp.astype(int)\n",
    "selected_feature_v2 = selected_feature[temp]\n",
    "selected_feature_v2 = np.sort(selected_feature_v2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集准确率（严格来说，我做完这一点之后就不可以进行任何操作，当然也不可以进行下一轮特征选择）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(min_samples_leaf = 1,min_samples_split = 6,max_depth = 31,random_state = 66)\n",
    "DT.fit(X_train_RELIEF_I_mutual, y_train)\n",
    "y_test_pred = DT.predict(X_test_RELIEF_I_mutual)\n",
    "accuracy(y_test,y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_feature_pred = DT.predict(test_feature[:,selected_feature])\n",
    "save_ndarray_to_csv(y_test_feature_pred,'test_label')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree_round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 16 features\n",
    "X_train_RELIEF_I_mutual_DT = X_train[:,selected_feature_v2]\n",
    "X_test_RELIEF_I_mutual_DT = X_test[:,selected_feature_v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(random_state = 66)\n",
    "score = cross_val_score(DT,X_train_RELIEF_I_mutual_DT,y_train,cv=4).mean()\n",
    "print('基尼系数得分: %.4f'%score)\n",
    "DT = DecisionTreeClassifier(criterion = 'entropy',random_state = 66)\n",
    "score = cross_val_score(DT,X_train_RELIEF_I_mutual_DT,y_train,cv=4).mean()\n",
    "print('熵得分: %.4f'%score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I choose gini index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###在大范围内画出max_depth这个参数变化曲线\n",
    "ScoreAll = []\n",
    "for i in range(10,100,10):\n",
    "    DT = DecisionTreeClassifier(max_depth = i,random_state = 66)\n",
    "    score = cross_val_score(DT,X_train_RELIEF_I_mutual_DT,y_train,cv=4).mean()\n",
    "    ScoreAll.append([i,score])\n",
    "ScoreAll = np.array(ScoreAll)\n",
    "\n",
    "max_score = np.where(ScoreAll==np.max(ScoreAll[:,1]))[0][0]\n",
    "print(\"最优参数以及最高得分:\",ScoreAll[max_score])  \n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(ScoreAll[:,0],ScoreAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###在小范围内画出max_depth这个参数变化曲线\n",
    "ScoreAll = []\n",
    "for i in range(20,40,1):\n",
    "    DT = DecisionTreeClassifier(max_depth = i,random_state = 66)\n",
    "    score = cross_val_score(DT,X_train_RELIEF_I_mutual_DT,y_train,cv=4).mean()\n",
    "    ScoreAll.append([i,score])\n",
    "ScoreAll = np.array(ScoreAll)\n",
    "\n",
    "max_score = np.where(ScoreAll==np.max(ScoreAll[:,1]))[0][0]\n",
    "print(\"最优参数以及最高得分:\",ScoreAll[max_score])  \n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(ScoreAll[:,0],ScoreAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暂定31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单独看看min_samples_split的变化趋势\n",
    "ScoreAll = []\n",
    "for i in range(2,30):\n",
    "    DT = DecisionTreeClassifier(max_depth = 31,min_samples_split = i,random_state = 66)\n",
    "    score = cross_val_score(DT,X_train_RELIEF_I_mutual_DT,y_train,cv=4).mean()\n",
    "    ScoreAll.append([i,score])\n",
    "ScoreAll = np.array(ScoreAll)\n",
    "\n",
    "max_score = np.where(ScoreAll==np.max(ScoreAll[:,1]))[0][0] ##这句话看似很长的，其实就是找出最高得分对应的索引\n",
    "print(\"最优参数以及最高得分:\",ScoreAll[max_score])  \n",
    "# print(ScoreAll[,0])\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(ScoreAll[:,0],ScoreAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暂定8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###调min_samples_leaf这个参数\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ScoreAll = []\n",
    "for i in range(1,30):\n",
    "    DT = DecisionTreeClassifier(min_samples_leaf = i,min_samples_split = 8,max_depth = 31,random_state = 66)\n",
    "    score = cross_val_score(DT,X_train_RELIEF_I_mutual_DT,y_train,cv=4).mean()\n",
    "    ScoreAll.append([i,score])\n",
    "ScoreAll = np.array(ScoreAll)\n",
    "\n",
    "max_score = np.where(ScoreAll==np.max(ScoreAll[:,1]))[0][0] ##这句话看似很长的，其实就是找出最高得分对应的索引\n",
    "print(\"最优参数以及最高得分:\",ScoreAll[max_score])  \n",
    "# print(ScoreAll[,0])\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(ScoreAll[:,0],ScoreAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据我们前边的一系列操作，我们确定因为max_depth在46附近，min_samples_split在8附近，min_samples_leaf在1是最优参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_depth、min_samples_leaf和min_samples_split一块儿调整  \n",
    "param_grid = {\n",
    "    'max_depth':np.arange(27, 33),\n",
    "    'min_samples_leaf':np.arange(1, 5),\n",
    "    'min_samples_split':np.arange(5, 10)}\n",
    "\n",
    "rfc = DecisionTreeClassifier(random_state=66)\n",
    "GS = GridSearchCV(rfc,param_grid,cv=4)\n",
    "GS.fit(X_train_RELIEF_I_mutual_DT,y_train)\n",
    "print(GS.best_params_)\n",
    "print(GS.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综合考虑mean和std，选择31、1、8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = GS.cv_results_\n",
    "my_mean_list = []\n",
    "my_std_list = []\n",
    "my_params_list = []\n",
    "\n",
    "for mean, std, params in zip(results['mean_test_score'], results['std_test_score'], results['params']):\n",
    "    my_mean_list.append(mean)\n",
    "    my_std_list.append(std)\n",
    "    my_params_list.append(params)\n",
    "\n",
    "my_mean_list = np.array(my_mean_list).reshape(len(my_mean_list),1)\n",
    "my_std_list = np.array(my_std_list).reshape(len(my_std_list),1)\n",
    "my_params_list_2 = pd.DataFrame(my_params_list)\n",
    "my_params_list_2 = my_params_list_2.to_numpy()\n",
    "my_GS_result = np.concatenate((my_mean_list,my_std_list),axis=1)\n",
    "my_GS_result = np.concatenate((my_GS_result,my_params_list_2),axis=1)\n",
    "save_ndarray_to_csv(my_GS_result,'GS_result_round2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(min_samples_leaf = 1,min_samples_split = 8,max_depth = 31,random_state = 66)\n",
    "score = cross_val_score(DT,X_train_RELIEF_I_mutual_DT,y_train,cv=4).mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv = X_train_RELIEF_I_mutual_DT\n",
    "y_cv = y_train\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k = 4 # a hyper-parameter\n",
    "stratified_kf = StratifiedKFold(n_splits = k)\n",
    "importance_DT = np.zeros((len(selected_feature_v2),))\n",
    "y_train_acc_sum = 0\n",
    "y_val_acc_sum = 0\n",
    "for train_index, val_index in stratified_kf.split(X_cv, y_cv):\n",
    "    \n",
    "    # split\n",
    "    X_train_cv, X_val_cv = X_cv[train_index], X_cv[val_index]\n",
    "    y_train_cv, y_val_cv = y_cv[train_index], y_cv[val_index]\n",
    "\n",
    "    # fit\n",
    "    DT = DecisionTreeClassifier(min_samples_leaf = 1,min_samples_split = 8,max_depth = 31,random_state = 66)\n",
    "    DT.fit(X_train_cv, y_train_cv)\n",
    "    # train\n",
    "    y_train_pred = DT.predict(X_train_cv)\n",
    "    y_train_acc = accuracy(y_train_cv,y_train_pred)\n",
    "    print(\"accuracy of train set: {}\".format(y_train_acc))\n",
    "    # val\n",
    "    y_val_pred = DT.predict(X_val_cv)\n",
    "    y_val_acc = accuracy(y_val_cv,y_val_pred)\n",
    "    print(\"accuracy of validation set: {}\".format(y_val_acc))\n",
    "    # importance\n",
    "    importance_DT += DT.feature_importances_\n",
    "    # sum\n",
    "    y_train_acc_sum += y_train_acc\n",
    "    y_val_acc_sum += y_val_acc\n",
    "\n",
    "# print\n",
    "y_train_acc_average = y_train_acc_sum / 4\n",
    "print(\"average accuracy of train set: {}\".format(y_train_acc_average))\n",
    "y_val_acc_average = y_val_acc_sum / 4\n",
    "print(\"average accuracy of val set: {}\".format(y_val_acc_average))\n",
    "\n",
    "# plot\n",
    "plt.plot(-np.sort(-importance_DT))\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('importance of decision tree')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(min_samples_leaf = 1,min_samples_split = 8,max_depth = 31,random_state = 66)\n",
    "DT.fit(X_train_RELIEF_I_mutual_DT, y_train)\n",
    "y_test_pred = DT.predict(X_test_RELIEF_I_mutual_DT)\n",
    "accuracy(y_test,y_test_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(n_estimators=3)\n",
    "# clf.fit(X_train_RELIEF_I_mutual_DT, y_train)\n",
    "# importance_RF = clf.feature_importances_\n",
    "\n",
    "# # accuracy of train set\n",
    "# y_train_pred = clf.predict(X_train_RELIEF_I_mutual_DT)\n",
    "# print(\"accuracy of train set: {}\".format(accuracy(y_train,y_train_pred)))\n",
    "\n",
    "# # accuracy of test set\n",
    "# y_test_pred = clf.predict(X_test_RELIEF_I_mutual_DT)\n",
    "# print(\"accuracy of test set: {}\".format(accuracy(y_test,y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try to visualize\n",
    "\n",
    "# # select 2 features randomly\n",
    "# train_feature_test = train_feature[:,[33, 45]]\n",
    "# # plot\n",
    "# plot_2D(train_feature_test, train_label)\n",
    "# plt.xlabel('feature 33') \n",
    "# plt.ylabel('feature 45')\n",
    "# plt.title('try to visualize')\n",
    "\n",
    "# # select 3 features randomly\n",
    "# train_feature_test = train_feature[:,[73, 109, 116]]\n",
    "# # plot\n",
    "# plot_3D(train_feature_test, train_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA()\n",
    "# pca.fit(X_train_RELIEF)\n",
    "# explained_var = pca.explained_variance_ratio_\n",
    "\n",
    "# # the scree plot\n",
    "# plt.bar(range(1, len(explained_var) + 1), explained_var)\n",
    "# plt.xlabel('Principal Component')\n",
    "# plt.ylabel('Explained Variance Ratio')\n",
    "# plt.show()\n",
    "\n",
    "# # the cumulative plot\n",
    "# cumulative_var = np.cumsum(explained_var)\n",
    "# plt.plot(range(1, len(cumulative_var) + 1), cumulative_var)\n",
    "# plt.xlabel('Number of components')\n",
    "# plt.ylabel('Cumulative explained variance')\n",
    "# plt.show()\n",
    "\n",
    "# # preserve\n",
    "# number_of_PC_preserverd = 10 # a hyper-parameter\n",
    "# X_train_RELIEF_PCA = pca.transform(X_train_RELIEF)\n",
    "# X_train_RELIEF_PCA = X_train_RELIEF_PCA[:,0:number_of_PC_preserverd]\n",
    "# X_val_RELIEF_PCA = pca.transform(X_val_RELIEF)\n",
    "# X_val_RELIEF_PCA = X_val_RELIEF_PCA[:,0:number_of_PC_preserverd]\n",
    "\n",
    "# # plot the first 2 principle components for visualization\n",
    "# plot_2D(X_train_RELIEF_PCA[:,[0,1]], y_train.reshape(len(y_train),1))\n",
    "# plt.xlabel('1st PC') \n",
    "# plt.ylabel('2nd PC')\n",
    "# plt.title('Use PCA to reduce dim to 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# lda = LinearDiscriminantAnalysis(n_components = 2)\n",
    "# train_feature_LDA = lda.fit_transform(train_feature, train_label.ravel())\n",
    "\n",
    "# # plot n_components = 2\n",
    "# plot_2D(train_feature_LDA, train_label)\n",
    "# plt.xlabel('LDA axis 1') \n",
    "# plt.ylabel('LDA axis 2')\n",
    "# plt.title('Use LDA to reduce dim to 2')\n",
    "\n",
    "# # plot n_components = 3\n",
    "# plot_3D(train_feature_LDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components = 3)\n",
    "train_feature_filted_by_tSNE_3D = tsne.fit_transform(train_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernelized PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import KernelPCA\n",
    "# kpca = KernelPCA(kernel='rbf', n_components=2)\n",
    "# train_feature_kpca = kpca.fit_transform(train_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use logistic regression for multi-classification 2\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# clf_LR = LogisticRegression(penalty='l1', multi_class=\"multinomial\", solver='saga', max_iter=10 ** 3,random_state=0)\n",
    "# clf_LR.fit(X_train_RELIEF, y_train)\n",
    "\n",
    "# # coef and intercept\n",
    "# a = clf_LR.coef_\n",
    "# b = clf_LR.intercept_\n",
    "\n",
    "# # accuracy of train set\n",
    "# y_train_pred = clf_LR.predict(X_train_RELIEF)\n",
    "# print(\"accuracy of train set: {}\".format(accuracy(y_train,y_train_pred)))\n",
    "\n",
    "# # accuracy of validation set\n",
    "# y_val_pred = clf_LR.predict(X_val_RELIEF)\n",
    "# print(\"accuracy of validation set: {}\".format(accuracy(y_val,y_val_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(30,30,30), activation='relu', max_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # accuracy of train set\n",
    "# y_train_pred = clf.predict(X_train)\n",
    "# print(\"accuracy of train set: {}\".format(accuracy(y_train,y_train_pred)))\n",
    "\n",
    "# # accuracy of validation set\n",
    "# y_val_pred = clf.predict(X_val_RELIEF)\n",
    "# print(\"accuracy of validation set: {}\".format(accuracy(y_val,y_val_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# clf = SVC(random_state=0, kernel='linear')\n",
    "# ovr = OneVsRestClassifier(clf)\n",
    "# ovr.fit(X_train, y_train)\n",
    "\n",
    "# # accuracy of train set\n",
    "# y_train_pred = clf_LR.predict(X_train)\n",
    "# print(\"accuracy of train set: {}\".format(accuracy(y_train,y_train_pred)))\n",
    "\n",
    "# # accuracy of validation set\n",
    "# y_val_pred = clf_LR.predict(X_val_RELIEF)\n",
    "# print(\"accuracy of validation set: {}\".format(accuracy(y_val,y_val_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# clf = xgb.XGBClassifier(booster = 'gbtree', num_class = 4, use_label_encoder = False, eval_metric = 'mlogloss')\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # accuracy of train set\n",
    "# y_train_pred = clf_LR.predict(X_train)\n",
    "# print(\"accuracy of train set: {}\".format(accuracy(y_train,y_train_pred)))\n",
    "\n",
    "# # accuracy of validation set\n",
    "# y_val_pred = clf_LR.predict(X_val_RELIEF)\n",
    "# print(\"accuracy of validation set: {}\".format(accuracy(y_val,y_val_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_2022FA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "183f961500e3762240ea4c2192e53c295752fca9a10f707371896b6e323d32f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
